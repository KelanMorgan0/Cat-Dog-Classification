{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Cat-Dog Classification\n",
    "\n",
    "data received from [Kaggle Cats and Dogs Dataset](https://www.microsoft.com/en-us/download/details.aspx?id=54765)\n",
    "\n",
    "# Imports"
   ],
   "id": "98f5c9a389741f94"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-23T16:58:13.463189Z",
     "start_time": "2025-03-23T16:58:11.712698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T16:58:17.159041Z",
     "start_time": "2025-03-23T16:58:17.153849Z"
    }
   },
   "cell_type": "code",
   "source": "print(tf.__version__)",
   "id": "4809b0c0bbad1136",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Take in the images and label them dog and cat",
   "id": "aa67c30e2c955701"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T16:59:34.006971Z",
     "start_time": "2025-03-23T16:58:20.097573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "# load all dog data\n",
    "for img_name in os.listdir(\"Data/Dog\"):\n",
    "    img_path = os.path.join(\"Data/Dog\", img_name)\n",
    "\n",
    "    #re-size images to 64 by 64\n",
    "    img = Image.open(img_path).resize((64, 64))\n",
    "    img = np.array(img) / 255.0\n",
    "\n",
    "    # add images to arrays\n",
    "    X.append(img)\n",
    "    y.append(\"Dog\")\n",
    "\n",
    "# load all cat data\n",
    "for img_name in os.listdir(\"Data/Cat\"):\n",
    "    img_path = os.path.join(\"Data/Cat\", img_name)\n",
    "\n",
    "    #re-size images to 64 by 64\n",
    "    img = Image.open(img_path).resize((64, 64))\n",
    "    img = np.array(img) / 255.0\n",
    "\n",
    "    # add images to arrays\n",
    "    X.append(img)\n",
    "    y.append(\"cat\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ],
   "id": "da62ed9e3c352950",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kelan\\OneDrive\\Documents\\GitHub\\Cat-Dog-Classification\\venv\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (24998, 64, 64) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 28\u001B[39m\n\u001B[32m     25\u001B[39m     X.append(img)\n\u001B[32m     26\u001B[39m     y.append(\u001B[33m\"\u001B[39m\u001B[33mcat\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m X = \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     29\u001B[39m y = np.array(y)\n",
      "\u001B[31mValueError\u001B[39m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (24998, 64, 64) + inhomogeneous part."
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# shuffle and split the data into test and training",
   "id": "e5fb97b252b2bf5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:26:08.555677Z",
     "start_time": "2025-03-23T17:26:08.525488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# get validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ],
   "id": "3a294dfa94bd7a86",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create CNN Model",
   "id": "45826077fb06a130"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T16:40:40.720608Z",
     "start_time": "2025-03-23T16:40:40.516234Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kelan\\OneDrive\\Documents\\GitHub\\Cat-Dog-Classification\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 6,
   "source": [
    "# Specify the number of filters and their sizes\n",
    "# Dropout randomly drops half the neurons form the dense call (prevents overfitting)\n",
    "# Dense 1 is classification of cat or dog\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ],
   "id": "d184dfd51c29cc8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train the model\n",
    "- x_train = image data\n",
    "- y_train = labels\n",
    "- epochs =  "
   ],
   "id": "7dd59fc391e65fa5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model = model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_val, y_val))",
   "id": "81568f8df46fb842"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
